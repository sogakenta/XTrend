# XTrend 統合仕様書

- **日付**: 2026-02-17
- **番号**: 2026-02-17-001
- **ステータス**: ドラフト
- **関連**: 001, 002, 003, 004

---

## 1. プロジェクト概要

### 目的

X (Twitter) のトレンドデータを収集・可視化するWebアプリ。競合（trends24.in, twittrend.jp）が提供していない「シグナル情報」で差別化する。

### 差別化ポイント

| 機能 | trends24.in | twittrend.jp | XTrend |
|------|-------------|--------------|--------|
| 順位変動（↑12, ↓5） | なし | なし | **対応** |
| 地域数表示（5地域） | なし | なし | **対応** |
| 継続時間（3時間） | 最長のみ | なし | **対応** |
| NEWバッジ | あり | なし | **対応** |
| 横並び比較 | なし | なし | **対応** |

### システム構成

```
[X API] → [Cloud Run: Batch] → [Supabase: PostgreSQL]
                                       ↓
[ユーザー] → [Next.js (ISR)] ←─────────┘
```

- **Batch**: 1時間に1回、X APIからトレンドを取得してDBに保存
- **Web**: ISRでページをキャッシュし、DBからトレンド+シグナルを取得して表示

---

## 2. 機能仕様

### 2.1 シグナル定義

| シグナル | 定義 | 表示例 |
|----------|------|--------|
| `rankChange` | **ちょうど1時間前**の同一地域での順位との差 | ↑12, ↓5, → |
| `regionCount` | **同一時点**でトレンド入りしている地域数 | 5地域 |
| `durationHours` | **連続して**トップ50に入っている時間数 | 3時間 |

### 2.2 バッジ定義

| バッジ | 条件 |
|--------|------|
| **NEW** | 対象時点に存在し、直前24時間に同一地域で**未出現** |
| **再浮上** | 直前1時間には不在だが、24時間内に出現履歴あり |
| (なし) | 直前1時間にも存在（継続中） |

### 2.3 時間軸プリセット

```
現在, 1h前, 3h前, 6h前, 12h前, 24h前, 48h前, 72h前
```

- **トップページ**: 固定3カラム（現在 / 1h / 3h）
- **地域ページ**: タブで切替
- **自由入力**: 初期リリースでは見送り（キャッシュキー爆発防止）

### 2.4 対象地域

| フェーズ | 地域数 | 地域 |
|----------|--------|------|
| MVP | 3 | 日本全国, 東京, 大阪 |
| 将来 | 53 | 全国 + 都道府県 |

---

## 3. 現状の問題点

### 3.1 意味上のバグ（正しさの問題）

| 問題 | 現状 | あるべき姿 | 影響 |
|------|------|-----------|------|
| `rankChange`の比較対象 | 「1時間前**以前**の最後の出現」と比較 | 「**ちょうど1時間前**」と比較 | 順位変動が不正確 |
| `durationHours`の計算 | 単純な出現回数カウント | **連続した**時間数のカウント | 継続時間が過大表示 |
| 欠損時の表示 | 「1時間前」と表示しつつ古いデータを使用 | 欠損時は「不明」または非表示 | ラベルが嘘になる |

### 3.2 負荷の問題

| 問題 | 原因 | 影響 |
|------|------|------|
| 無制限履歴取得 | `lte()`で範囲指定、`limit`なし | データ増加で負荷が線形増大 |
| `max_rows=1000`到達 | 4〜8日で上限に達する | シグナルが欠落・不正確に |
| ISR過剰再生成 | `revalidate=300`（5分） | 1時間に12回、11回は無駄 |

### 3.3 破綻タイムライン

| 運用期間 | 1地域の累積行数 | 問題 |
|----------|----------------|------|
| **4〜8日** | 4,800〜9,600 | **max_rows=1000で切り捨て開始** |
| 1ヶ月 | 36,000 | 深刻な精度劣化 |
| 6ヶ月 | 216,000 | 完全に機能しない |

**結論**: 運用開始から1週間以内に問題が顕在化する

### 3.4 データ反映タイミングのズレ

#### 現状の設計

- **Batch**: Cloud Schedulerで毎時01分に起動
- **captured_at**: 正時に丸められる（12:01実行 → captured_at=12:00）
- **ISR**: `revalidate=300`（5分ごとに再生成可能）

#### 問題

| 時刻 | イベント | 問題 |
|------|---------|------|
| 12:00 | ISR再生成 | まだingest未完了、前回の11:00データを表示 |
| 12:01 | ingest開始 | - |
| 12:02 | ingest完了 | DBに12:00データが入る |
| 12:05 | ISR再生成 | **やっと12:00データが反映** |

**最大5分のタイムラグ**が発生し、ユーザーは古いデータを見る可能性がある。

#### 解決策

| 方式 | 説明 | 採用 |
|------|------|------|
| **On-Demand Revalidation** | ingest完了後にキャッシュを明示的に無効化 | ✅ 推奨 |
| revalidate=3600 + 許容 | 1時間キャッシュで「最大1時間遅れ」を許容 | ✅ 暫定対応 |
| ISR開始時刻をずらす | Next.jsでは制御困難 | ❌ |

**推奨フロー**:
```
12:01 Batch起動
12:02 ingest完了 → POST /api/revalidate
12:02 Next.jsキャッシュ無効化
12:02 次回アクセスで最新データ反映
```

---

## 4. 負荷の数値分析

### 4.1 現状の負荷（1リクエストあたり）

| クエリ | 取得行数 | 問題 |
|--------|---------|------|
| previousSnapshots（順位変動用） | 無制限（全履歴） | 1週間で1,000行超え |
| regionSnapshots（地域数用） | 最大2,650行（53地域×50件） | max_rows到達リスク |
| durationSnapshots（継続時間用） | 最大1,200行（24h×50件） | 無駄に広範囲 |
| **合計** | 約6,608行 | 過剰 |

### 4.2 最適化後の負荷（1リクエストあたり）

| クエリ | 取得行数 | 方法 |
|--------|---------|------|
| previousSnapshots | 50行（固定） | 時点固定クエリ |
| regionSnapshots | 1行 | DB側で`count(distinct woeid)` |
| durationSnapshots | 50行（固定） | 連続判定をDB側で実行 |
| **合計** | 約100行 | **98%削減** |

### 4.3 ISR再生成の負荷

| 設定 | 再生成回数/時 | DB読み取り行数/日（3地域） |
|------|-------------|---------------------------|
| 現状 (revalidate=300) | 最大12回 | 約190万行 |
| 改善後 (revalidate=3600) | 最大1回 | 約1.6万行 |
| **削減率** | 92% | 99% |

### 4.4 53地域スケール時の見積もり

| 項目 | 現状設計 | 最適化後 |
|------|---------|---------|
| 1リクエストの読み取り | 約35万行 | 約100行 |
| スケール可否 | **破綻** | 問題なし |

---

## 5. 解決策

### 5.1 即時対応（Phase 0）

| 対策 | 効果 | 工数 |
|------|------|------|
| **クエリ時点固定** | 無制限取得を50行固定に | 0.5日 |
| **revalidate=3600** | ISR再生成を92%削減 | 0.5時間 |
| **offset制限** | プリセット値のみ許可 | 0.5時間 |

#### クエリ時点固定の方法

「1時間前」を取得する際、以下のように変更:

| 現状 | 改善後 |
|------|--------|
| 「1時間前**以前**」の全データを取得 | まず「1時間前に最も近い時点」を特定し、その時点のデータのみ取得 |

#### 時点解決のモード

| 用途 | モード | 動作 |
|------|--------|------|
| rankChange | `exact_or_null` | ちょうど1時間前がなければ`null`（「不明」表示） |
| 履歴表示 | `nearest_before` | 欠損時は最寄りの時点を採用 |

### 5.2 中期対応（Phase 1）

| 対策 | 効果 | 工数 |
|------|------|------|
| **シグナル事前計算テーブル** | 読み取り時は計算済みデータを取得するだけ | 2〜4日 |
| **ingest連携** | バッチ完了後に1回だけシグナル計算 | 上記に含む |

#### 事前計算テーブルの構成

| テーブル | 役割 |
|----------|------|
| `trend_snapshot` | 生データ（ソースオブトゥルース） |
| `trend_signal_hourly` | 計算済みシグナル |

#### データフロー

```
[X API] → [Batch] → trend_snapshot（生データ保存）
                   ↓
            compute_signals（シグナル計算）
                   ↓
            trend_signal_hourly（計算済み保存）

[Web] → trend_snapshot JOIN trend_signal_hourly
      → 計算不要、取得するだけ
```

### 5.3 長期対応（Phase 2）

| 対策 | 効果 | 工数 |
|------|------|------|
| **On-Demand Revalidation** | ingest完了時のみ再生成 | 1日 |
| **ホットページJSON配信** | DB負荷をさらに削減 | 1〜2日 |

#### On-Demand Revalidationの仕組み

```
[Batch] → ingest完了
        → POST /api/revalidate（署名付き）
        → Next.jsキャッシュ無効化
        → 次回アクセス時に再生成
```

| ingest結果 | 再検証 | 理由 |
|-----------|--------|------|
| succeeded | 全体 | 全地域のデータが更新された |
| partial | ホームのみ | 一部地域が失敗 |
| failed | なし | 前回の良データを維持 |

---

## 6. リスクと対策

### 6.1 見落としやすいリスク

| リスク | 影響 | 対策 |
|--------|------|------|
| **欠損時の「1時間前」ラベル** | ユーザーに嘘をつく | `exact_or_null`モードで「不明」表示 |
| **部分失敗run** | regionCountが過小表示 | `region_count_is_partial`フラグで明示 |
| **任意offset受け入れ** | キャッシュキーが増殖 | プリセット値のみ許可 |
| **Cloud Run複数インスタンス** | キャッシュがインスタンスローカル | 単一インスタンス or 共有cache handler |

### 6.2 やりすぎ/やらなさすぎの判断基準

| 基準 | 対応タイミング |
|------|---------------|
| 正しさが壊れる兆候 | max_rows到達やシグナル欠損が出たら**即対応** |
| コストが閾値超過 | Egress/DB使用量が無料枠70%継続超過なら次段階へ |
| 速度が体験を壊す | ページ生成P95が目標超えたら事前計算へ |
| 複雑性の純増 | 障害面積が大きく増えるなら見送る |

---

## 7. 見送り事項

| 事項 | 理由 |
|------|------|
| DB移行（Neon等） | 今の課題はDB製品ではない |
| マテリアライズドビュー | 53地域でrefreshコスト問題 |
| 完全SSG | 動的ページ運用を切る判断が必要 |
| 全シグナル一括実装 | まず最小差別化で検証 |

---

## 8. 実装優先度

| 順序 | タスク | 理由 | 工数 |
|------|--------|------|------|
| **P0-1** | `rankChange`の時点固定 | 意味上のバグ修正 | 0.5日 |
| **P0-2** | `durationHours`の連続判定修正 | 意味上のバグ修正 | 0.5日 |
| **P0-3** | `regionCount`の時点固定+DB集計化 | max_rows対策 | 0.5日 |
| **P1-1** | `revalidate=3600`に変更 | 即効性あり | 0.5時間 |
| **P1-2** | offsetのプリセット制限 | キャッシュキー爆発防止 | 0.5時間 |
| **P2** | シグナル事前計算テーブル | スケール対応 | 2〜4日 |
| **P3** | On-Demand Revalidation | 鮮度向上 | 1日 |

---

## 9. Supabase制限との照合

| リソース | Free | Pro | XTrend想定（1年） |
|----------|------|-----|------------------|
| DBサイズ | 500MB | 8GB | 約300MB |
| Egress | 5GB | 250GB | 問題なし（ISR活用） |
| max_rows | 1,000 | 設定可 | **Phase 0で対応必須** |

**結論**: Phase 0を完了すればFreeプランでも1年以上運用可能

---

## 10. ISR再生成頻度の選択肢

**前提**: X APIからのデータ取得（ingest）は1時間に1回で固定。ここではフロント（ISR）の再生成頻度を検討する。

### 10.1 revalidate設定の比較

| 設定 | 再生成/時 | 最大遅延 | DB読み取り/時 | 評価 |
|------|----------|---------|--------------|------|
| revalidate=300（現状） | 12回 | 5分 | 12回 | 過剰（11回は無駄） |
| **revalidate=600** | 6回 | 10分 | 6回 | **バランス良** |
| revalidate=1800 | 2回 | 30分 | 2回 | 許容範囲 |
| revalidate=3600 | 1回 | 60分 | 1回 | 最小負荷だが遅延大 |

### 10.2 10分更新（revalidate=600）のメリット

| 観点 | 説明 |
|------|------|
| **タイムラグ軽減** | ingest完了（12:02）後、最大10分（12:12）で反映 |
| **負荷軽減** | 現状の半分（12回→6回） |
| **On-Demand不要** | 複雑な仕組みなしで「まし」になる |
| **実装コスト** | 1行変更するだけ |

### 10.3 タイムライン比較

#### revalidate=300（現状）
```
12:00 ISR再生成（古い11:00データ）
12:02 ingest完了
12:05 ISR再生成（12:00データ反映）← 3分後
```

#### revalidate=600（10分）
```
12:00 ISR再生成（古い11:00データ）
12:02 ingest完了
12:10 ISR再生成（12:00データ反映）← 8分後
```

#### revalidate=3600（1時間）
```
12:00 ISR再生成（古い11:00データ）
12:02 ingest完了
13:00 ISR再生成（12:00データ反映）← 58分後
```

### 10.4 推奨

| フェーズ | 設定 | 理由 |
|----------|------|------|
| **MVP** | revalidate=600（10分） | 負荷半減、タイムラグ許容範囲 |
| 後続 | + On-Demand Revalidation | ingest直後に即反映 |

### 10.5 On-Demand Revalidationとの組み合わせ

| 構成 | 動作 |
|------|------|
| revalidate=600 のみ | 最大10分遅延、シンプル |
| revalidate=3600 + On-Demand | 通常は即反映、Webhook失敗時は最大1時間 |
| **revalidate=600 + On-Demand** | 通常は即反映、Webhook失敗時も最大10分 |

**推奨**: `revalidate=600 + On-Demand`（フォールバックとして10分を維持）

---

## 11. Open Questions

| 項目 | 選択肢 | 現状 |
|------|--------|------|
| Web本番環境 | Vercel or Cloud Run | 未決定 |
| Cloud Runインスタンス数 | 1 or 複数 | 未決定 |
| `/term`ページの再検証 | 対象外 or 含める | 初期は対象外を推奨 |
| **ISR revalidate** | 600秒 / 1800秒 / 3600秒 | 600秒（10分）を推奨 |

---

## 付録A: 実装ログ（2026-02-17）

### 実装完了タスク

| タスク | ファイル | 内容 |
|--------|---------|------|
| P1-2 | `lib/constants.ts` | `VALID_OFFSETS`と`OFFSET_LABELS`を定義 |
| P1-2 | `components/TimeOffsetTabs.tsx` | 48h/72h追加、constantsからインポート |
| P1-2 | `app/place/[slug]/page.tsx` | offsetバリデーション強化（正規表現）、不正値はリダイレクト |
| P1-1 | `app/page.tsx` | `revalidate=600`（10分） |
| P1-1 | `app/place/[slug]/page.tsx` | `revalidate=600`（10分） |
| P0-1 | `lib/data.ts` | `resolveCapturedAt()`関数追加（exact_or_null/nearest_beforeモード） |
| P0-1 | `lib/data.ts` | `rankChange`を時点固定クエリに変更 |
| P0-3 | `lib/data.ts` | `regionCount`を同一`captured_at`で集計（範囲クエリ廃止） |
| P0-2 | `lib/data.ts` | `durationHours`を連続判定に変更（epoch ms比較） |

### Codexレビュー指摘への対応

| 指摘 | 対応 |
|------|------|
| `offset=1abc`が通る | 正規表現`/^\d+$/`で厳密チェック |
| 不正offsetでキャッシュキー爆発 | 不正値は`redirect()`でベースパスへ |
| `Z`と`+00:00`の文字列差 | epoch ms（数値）で比較 |
| `VALID_OFFSETS`がクライアントコンポーネントからエクスポート | `lib/constants.ts`に分離 |

### 変更ファイル一覧

```
apps/web/src/lib/constants.ts       # 新規作成
apps/web/src/lib/data.ts            # シグナル計算ロジック修正
apps/web/src/components/TimeOffsetTabs.tsx
apps/web/src/components/index.ts
apps/web/src/app/page.tsx
apps/web/src/app/place/[slug]/page.tsx
```

---

## 付録B: アーキテクチャ図

### 現フェーズ（MVP）

```
[X API]
   ↓
[Cloud Run: Batch] ─────→ [Supabase: PostgreSQL]
   │                              │
   │                              ↓
   │                      trend_snapshot (生データ)
   │
   └─(将来)─→ trend_signal_hourly (計算済み)

[ユーザー]
   ↓
[Next.js (ISR, revalidate=3600)]
   ↓
[Supabase: PostgreSQL]
```

### 将来フェーズ（スケール時）

```
[X API]
   ↓
[Cloud Run: Batch]
   ├─→ [Supabase: PostgreSQL] (ソースオブトゥルース)
   ├─→ [R2/S3: JSON] (配信用)
   └─→ POST /api/revalidate (キャッシュ無効化)

[ユーザー]
   ↓
[CDN Edge Cache]
   ↓
[Next.js (On-Demand Revalidation)]
   ↓
[JSON or Supabase]
```
